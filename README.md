# 🧠 Artificial Neural Network Experiments

This repository contains implementations of fundamental **Artificial Neural Network (ANN)** algorithms and concepts.  
Each experiment demonstrates a key concept — from simple perceptrons to advanced self-organizing models.

---

## 📋 List of Experiments

### ⚙️ **Experiment 3 – Perceptron Model for Logical Functions**
Implemented the **Perceptron algorithm** to simulate basic logical operations:
- 🔸 Logical AND  
- 🔸 Logical OR  
- 🔸 Logical NOT  

**Concept:**  
A perceptron is the simplest neural network model — a single-layer neuron that computes a weighted sum and applies an activation function to make predictions.

---

### 📈 **Experiment 4 – Plot Various Activation Functions**
Plotted the most commonly used **activation functions** in neural networks:
- Step Function  
- Sigmoid Function  
- Tanh Function  
- ReLU Function  
- Leaky ReLU Function  

**Concept:**  
Activation functions introduce **non-linearity**, enabling neural networks to learn complex and real-world relationships.

---

### 🧩 **Experiment 5 – Train a Feed Forward Neural Network**
Developed and trained a **Feed Forward Neural Network (FFNN)** on sample data.

**Concept:**  
In a feed-forward network, information moves in one direction — from input to output — and learning occurs using **gradient descent**.

---

### 🔗 **Experiment 6 – Hebb’s Learning Rule**
Implemented **Hebb’s Rule** for basic logical functions like AND and OR.

**Concept:**  
Hebbian learning follows the principle — *“Neurons that fire together, wire together.”*  
Weights are updated when input and output neurons are simultaneously active.

---

### 🔁 **Experiment 7 – Backpropagation in Feed Forward Neural Network**
Trained a **Feed Forward Neural Network** using the **Backpropagation algorithm**.

**Concept:**  
Backpropagation adjusts network weights in proportion to their contribution to the output error — forming the foundation of modern **deep learning**.

---

### 🧭 **Experiment 8 – Self-Organizing Map (SOM)**
Implemented the **Kohonen Self-Organizing Map (SOM)** for **unsupervised clustering**.

**Concept:**  
SOMs project high-dimensional input data into a **2D grid** while preserving topological relationships between data points.

---

### 🎯 **Experiment 9 – Learning Vector Quantization (LVQ)**
Implemented the **Learning Vector Quantization (LVQ)** algorithm.

**Concept:**  
LVQ is a **supervised learning** technique derived from SOM, used for pattern classification by fine-tuning class prototype vectors.

---

## 💻 Technologies Used
- Python 🐍  
- NumPy  
- Matplotlib  
- Scikit-learn (for some experiments)

---

## 📊 Output and Results
Each experiment includes:
- ✅ Source Code (`.py` / `.ipynb`)  
- 📈 Output Plots and Tables  
- 🧠 Concept Explanation and Comments  

---

## 🚀 How to Run

1. **Clone the repository**
   ```bash
   git clone https://github.com/<your-username>/ANN_LAB.git

2. Navigate to the project folder
```
cd ANN_LAB
